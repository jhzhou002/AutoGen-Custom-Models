#!/usr/bin/env python3
"""
æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹é…ç½®çš„ç¤ºä¾‹ä»£ç 
æ”¯æŒ Kimi-K2, DeepSeek-R1, Qwen3 ä¸‰ä¸ªæ¨¡å‹
"""

import asyncio
import yaml
from pathlib import Path
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.ui import Console


def load_model_config(config_file: str, model_name: str) -> dict:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½æŒ‡å®šæ¨¡å‹çš„é…ç½®"""
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    if model_name not in config:
        raise ValueError(f"æ¨¡å‹ {model_name} æœªåœ¨é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°")
    
    return config[model_name]['config']


async def test_model(model_name: str, model_config: dict, test_message: str):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*50}")
    print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"{'='*50}")
    
    try:
        # åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯
        model_client = OpenAIChatCompletionClient(**model_config)
        
        # åˆ›å»ºåŠ©æ‰‹ä»£ç†
        agent = AssistantAgent(
            name=f"{model_name}_assistant",
            model_client=model_client,
            system_message=f"ä½ æ˜¯ä¸€ä¸ªåŸºäº{model_name}æ¨¡å‹çš„AIåŠ©æ‰‹ï¼Œæ“…é•¿ç¼–ç¨‹å’Œé—®é¢˜è§£å†³ã€‚"
        )
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        print(f"å‘é€æ¶ˆæ¯: {test_message}")
        print("-" * 30)
        
        response = await agent.run(task=test_message)
        print(f"æ¨¡å‹å›å¤: {response.messages[-1].content}")
        
        # å…³é—­å®¢æˆ·ç«¯
        await model_client.close()
        
        print(f"âœ… {model_name} æµ‹è¯•æˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ {model_name} æµ‹è¯•å¤±è´¥: {str(e)}")


async def test_coding_capability(model_name: str, model_config: dict):
    """æµ‹è¯•æ¨¡å‹çš„ç¼–ç¨‹èƒ½åŠ›"""
    coding_task = """
    è¯·ç¼–å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹ï¼Œè¦æ±‚:
    1. ä½¿ç”¨é€’å½’æ–¹å¼å®ç°
    2. æ·»åŠ è®°å¿†åŒ–ä¼˜åŒ–é¿å…é‡å¤è®¡ç®—
    3. åŒ…å«è¯¦ç»†çš„æ³¨é‡Š
    4. æä¾›ä½¿ç”¨ç¤ºä¾‹
    """
    
    print(f"\n{'='*50}")
    print(f"æµ‹è¯• {model_name} ç¼–ç¨‹èƒ½åŠ›")
    print(f"{'='*50}")
    
    try:
        model_client = OpenAIChatCompletionClient(**model_config)
        
        agent = AssistantAgent(
            name=f"{model_name}_coder",
            model_client=model_client,
            system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¨‹åºå‘˜ï¼Œæ“…é•¿ç¼–å†™é«˜è´¨é‡ã€é«˜æ•ˆçš„ä»£ç ã€‚"
        )
        
        response = await agent.run(task=coding_task)
        print(f"ç¼–ç¨‹ä»»åŠ¡å›å¤:\n{response.messages[-1].content}")
        
        await model_client.close()
        print(f"âœ… {model_name} ç¼–ç¨‹èƒ½åŠ›æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ {model_name} ç¼–ç¨‹èƒ½åŠ›æµ‹è¯•å¤±è´¥: {str(e)}")


async def test_multi_agent_conversation():
    """æµ‹è¯•å¤šä»£ç†å¯¹è¯ - ä½¿ç”¨ä¸åŒæ¨¡å‹çš„ä»£ç†è¿›è¡Œåä½œ"""
    print(f"\n{'='*50}")
    print("å¤šä»£ç†åä½œæµ‹è¯•")
    print(f"{'='*50}")
    
    config_file = Path(__file__).parent.parent / "custom_models_config.yaml"
    
    try:
        # åŠ è½½é…ç½®
        kimi_config = load_model_config(str(config_file), "kimi_k2")
        qwen_config = load_model_config(str(config_file), "qwen3_coder")
        
        # åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯
        kimi_client = OpenAIChatCompletionClient(**kimi_config)
        qwen_client = OpenAIChatCompletionClient(**qwen_config)
        
        # åˆ›å»ºä»£ç†
        architect = AssistantAgent(
            name="architect",
            model_client=kimi_client,
            system_message="ä½ æ˜¯ä¸€ä¸ªè½¯ä»¶æ¶æ„å¸ˆï¼Œè´Ÿè´£è®¾è®¡ç¨‹åºçš„æ•´ä½“æ¶æ„å’Œæ¥å£ã€‚"
        )
        
        coder = AssistantAgent(
            name="coder", 
            model_client=qwen_client,
            system_message="ä½ æ˜¯ä¸€ä¸ªç¨‹åºå‘˜ï¼Œè´Ÿè´£æ ¹æ®æ¶æ„è®¾è®¡å®ç°å…·ä½“ä»£ç ã€‚"
        )
        
        from autogen_agentchat.teams import RoundRobinGroupChat
        from autogen_agentchat.conditions import MaxMessageTermination
        
        # åˆ›å»ºå›¢é˜Ÿ
        team = RoundRobinGroupChat([architect, coder])
        
        # ä»»åŠ¡
        task = """
        è®¾è®¡å¹¶å®ç°ä¸€ä¸ªç®€å•çš„ä»»åŠ¡ç®¡ç†ç³»ç»Ÿï¼Œè¦æ±‚:
        1. å¯ä»¥æ·»åŠ ã€åˆ é™¤ã€æ›´æ–°ä»»åŠ¡
        2. æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§
        3. å¯ä»¥æŒ‰çŠ¶æ€è¿‡æ»¤ä»»åŠ¡
        4. è¯·å…ˆè®¨è®ºæ¶æ„è®¾è®¡ï¼Œç„¶åå®ç°ä»£ç 
        """
        
        print("å¼€å§‹å¤šä»£ç†åä½œ...")
        
        # ä½¿ç”¨ Console UI è¿›è¡Œäº¤äº’
        result = await Console(
            team.run_stream(
                task=task,
                termination_condition=MaxMessageTermination(max_messages=6)
            )
        )
        
        # å…³é—­å®¢æˆ·ç«¯
        await kimi_client.close()
        await qwen_client.close()
        
        print("âœ… å¤šä»£ç†åä½œæµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ å¤šä»£ç†åä½œæµ‹è¯•å¤±è´¥: {str(e)}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹é…ç½®...")
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = Path(__file__).parent.parent / "custom_models_config.yaml"
    
    if not config_file.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_file}")
        return
    
    # æµ‹è¯•æ¶ˆæ¯
    test_message = "ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¼–ç¨‹æ–¹é¢çš„ä¸“é•¿ã€‚"
    
    # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
    models_to_test = ["kimi_k2", "deepseek_r1", "qwen3_coder"]
    
    for model_name in models_to_test:
        try:
            model_config = load_model_config(str(config_file), model_name)
            await test_model(model_name, model_config, test_message)
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½ {model_name} é…ç½®: {str(e)}")
    
    # æµ‹è¯•ç¼–ç¨‹èƒ½åŠ› (é‡ç‚¹æµ‹è¯• Kimi-K2 å’Œ Qwen3)
    for model_name in ["kimi_k2", "qwen3_coder"]:
        try:
            model_config = load_model_config(str(config_file), model_name)
            await test_coding_capability(model_name, model_config)
        except Exception as e:
            print(f"âŒ æ— æ³•æµ‹è¯• {model_name} ç¼–ç¨‹èƒ½åŠ›: {str(e)}")
    
    # æµ‹è¯•å¤šä»£ç†åä½œ
    await test_multi_agent_conversation()
    
    print(f"\n{'='*50}")
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"{'='*50}")


if __name__ == "__main__":
    asyncio.run(main())