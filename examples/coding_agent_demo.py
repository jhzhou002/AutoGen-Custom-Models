#!/usr/bin/env python3
"""
ç¼–ç¨‹ä»£ç†æ¼”ç¤º - å±•ç¤º Kimi-K2 å’Œ Qwen3 çš„ç¼–ç¨‹èƒ½åŠ›
"""

import asyncio
import yaml
from pathlib import Path
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import MaxMessageTermination
from autogen_agentchat.ui import Console


async def create_coding_agents():
    """åˆ›å»ºç¼–ç¨‹ç›¸å…³çš„ä»£ç†"""
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = Path(__file__).parent.parent / "custom_models_config.yaml"
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»º Kimi-K2 æ¶æ„å¸ˆ
    kimi_config = config['kimi_k2']['config']
    kimi_client = OpenAIChatCompletionClient(**kimi_config)
    
    architect = AssistantAgent(
        name="æ¶æ„å¸ˆ",
        model_client=kimi_client,
        system_message="""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è½¯ä»¶æ¶æ„å¸ˆï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. åˆ†æéœ€æ±‚å¹¶è®¾è®¡åˆç†çš„ç³»ç»Ÿæ¶æ„
2. é€‰æ‹©åˆé€‚çš„è®¾è®¡æ¨¡å¼å’ŒæŠ€æœ¯æ ˆ
3. è€ƒè™‘ä»£ç çš„å¯ç»´æŠ¤æ€§ã€å¯æ‰©å±•æ€§å’Œæ€§èƒ½
4. æä¾›æ¸…æ™°çš„æ¶æ„å›¾å’Œæ¥å£è®¾è®¡
è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œå¹¶ä¿æŒä¸“ä¸šå’Œè¯¦ç»†ã€‚"""
    )
    
    # åˆ›å»º Qwen3 ç¨‹åºå‘˜
    qwen_config = config['qwen3_coder']['config']
    qwen_client = OpenAIChatCompletionClient(**qwen_config)
    
    programmer = AssistantAgent(
        name="ç¨‹åºå‘˜",
        model_client=qwen_client,
        system_message="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¨‹åºå‘˜ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. æ ¹æ®æ¶æ„è®¾è®¡å®ç°é«˜è´¨é‡çš„ä»£ç 
2. éµå¾ªPythonæœ€ä½³å®è·µå’ŒPEPè§„èŒƒ
3. ç¼–å†™æ¸…æ™°çš„æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²
4. è¿›è¡Œé€‚å½“çš„é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ£€æŸ¥
5. æä¾›ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç 
è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä»£ç è¦å®Œæ•´ä¸”å¯æ‰§è¡Œã€‚"""
    )
    
    # åˆ›å»º DeepSeek-R1 å®¡æŸ¥å‘˜ï¼ˆç”¨äºä»£ç å®¡æŸ¥ï¼‰
    deepseek_config = config['deepseek_r1']['config']
    deepseek_client = OpenAIChatCompletionClient(**deepseek_config)
    
    reviewer = AssistantAgent(
        name="ä»£ç å®¡æŸ¥å‘˜",
        model_client=deepseek_client,
        system_message="""ä½ æ˜¯ä¸€ä¸ªä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. å®¡æŸ¥ä»£ç çš„æ­£ç¡®æ€§ã€æ€§èƒ½å’Œå®‰å…¨æ€§
2. è¯†åˆ«æ½œåœ¨çš„bugå’Œæ”¹è¿›ç‚¹
3. æ£€æŸ¥ä»£ç æ˜¯å¦ç¬¦åˆæœ€ä½³å®è·µ
4. æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®
5. è¯„ä¼°ä»£ç çš„å¯è¯»æ€§å’Œç»´æŠ¤æ€§
è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œæä¾›è¯¦ç»†çš„å®¡æŸ¥æ„è§ã€‚"""
    )
    
    return architect, programmer, reviewer, [kimi_client, qwen_client, deepseek_client]


async def coding_collaboration_demo():
    """ç¼–ç¨‹åä½œæ¼”ç¤º"""
    
    print("ğŸš€ å¯åŠ¨ç¼–ç¨‹å›¢é˜Ÿåä½œæ¼”ç¤º...")
    print("ğŸ‘¥ å›¢é˜Ÿæˆå‘˜:")
    print("   ğŸ—ï¸  æ¶æ„å¸ˆ (Kimi-K2) - è´Ÿè´£ç³»ç»Ÿè®¾è®¡")
    print("   ğŸ’» ç¨‹åºå‘˜ (Qwen3) - è´Ÿè´£ä»£ç å®ç°") 
    print("   ğŸ” å®¡æŸ¥å‘˜ (DeepSeek-R1) - è´Ÿè´£ä»£ç å®¡æŸ¥")
    print("="*80)
    
    # åˆ›å»ºä»£ç†
    architect, programmer, reviewer, clients = await create_coding_agents()
    
    # åˆ›å»ºå›¢é˜Ÿ
    team = RoundRobinGroupChat([architect, programmer, reviewer])
    
    # ç¼–ç¨‹ä»»åŠ¡
    task = """
    è®¾è®¡å¹¶å®ç°ä¸€ä¸ªå­¦ç”Ÿæˆç»©ç®¡ç†ç³»ç»Ÿï¼Œè¦æ±‚ï¼š

    åŠŸèƒ½éœ€æ±‚ï¼š
    1. æ·»åŠ å­¦ç”Ÿä¿¡æ¯ï¼ˆå§“åã€å­¦å·ã€ç­çº§ï¼‰
    2. å½•å…¥æˆç»©ï¼ˆç§‘ç›®ã€åˆ†æ•°ï¼‰
    3. è®¡ç®—å­¦ç”Ÿå¹³å‡åˆ†å’Œæ€»åˆ†
    4. æŒ‰æˆç»©æ’åºæ˜¾ç¤ºå­¦ç”Ÿåˆ—è¡¨
    5. æŸ¥è¯¢æŒ‡å®šå­¦ç”Ÿçš„æˆç»©è¯¦æƒ…
    6. ç»Ÿè®¡å„ç§‘ç›®çš„å¹³å‡åˆ†

    æŠ€æœ¯è¦æ±‚ï¼š
    1. ä½¿ç”¨é¢å‘å¯¹è±¡ç¼–ç¨‹
    2. æ•°æ®æŒä¹…åŒ–ï¼ˆæ–‡ä»¶æˆ–æ•°æ®åº“ï¼‰
    3. å¼‚å¸¸å¤„ç†
    4. æä¾›å‘½ä»¤è¡Œç•Œé¢
    5. ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ³¨é‡Šå®Œæ•´

    è¯·æŒ‰ä»¥ä¸‹æµç¨‹è¿›è¡Œï¼š
    1. æ¶æ„å¸ˆï¼šåˆ†æéœ€æ±‚ï¼Œè®¾è®¡ç³»ç»Ÿæ¶æ„å’Œç±»ç»“æ„
    2. ç¨‹åºå‘˜ï¼šæ ¹æ®è®¾è®¡å®ç°å®Œæ•´ä»£ç 
    3. å®¡æŸ¥å‘˜ï¼šå®¡æŸ¥ä»£ç è´¨é‡å¹¶æå‡ºæ”¹è¿›å»ºè®®
    """
    
    try:
        print("ğŸ“‹ ä»»åŠ¡æè¿°:")
        print(task)
        print("\nğŸƒâ€â™‚ï¸ å¼€å§‹åä½œ...")
        print("="*80)
        
        # å¼€å§‹åä½œ
        result = await Console(
            team.run_stream(
                task=task,
                termination_condition=MaxMessageTermination(max_messages=6)
            )
        )
        
        print("\nâœ… ç¼–ç¨‹åä½œæ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
    
    finally:
        # å…³é—­æ‰€æœ‰å®¢æˆ·ç«¯
        for client in clients:
            await client.close()


async def single_model_coding_test():
    """å•æ¨¡å‹ç¼–ç¨‹èƒ½åŠ›æµ‹è¯•"""
    
    print("\n" + "="*80)
    print("ğŸ¯ å•æ¨¡å‹ç¼–ç¨‹èƒ½åŠ›æµ‹è¯•")
    print("="*80)
    
    config_file = Path(__file__).parent.parent / "custom_models_config.yaml"
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æµ‹è¯•ä»»åŠ¡
    coding_tasks = [
        {
            "title": "ç®—æ³•å®ç°",
            "task": "å®ç°å¿«é€Ÿæ’åºç®—æ³•ï¼ŒåŒ…å«è¯¦ç»†æ³¨é‡Šå’Œæ—¶é—´å¤æ‚åº¦åˆ†æ"
        },
        {
            "title": "æ•°æ®ç»“æ„",
            "task": "å®ç°ä¸€ä¸ªé“¾è¡¨ç±»ï¼Œæ”¯æŒæ’å…¥ã€åˆ é™¤ã€æŸ¥æ‰¾å’Œéå†æ“ä½œ"
        },
        {
            "title": "å®é™…åº”ç”¨",
            "task": "ç¼–å†™ä¸€ä¸ªç®€å•çš„è®¡ç®—å™¨ç¨‹åºï¼Œæ”¯æŒå››åˆ™è¿ç®—å’Œæ‹¬å·"
        }
    ]
    
    # æµ‹è¯• Kimi-K2 å’Œ Qwen3
    models_to_test = ["kimi_k2", "qwen3_coder"]
    
    for model_name in models_to_test:
        print(f"\nğŸ¤– æµ‹è¯•æ¨¡å‹: {model_name}")
        print("-" * 50)
        
        model_config = config[model_name]['config']
        client = OpenAIChatCompletionClient(**model_config)
        
        agent = AssistantAgent(
            name=f"{model_name}_coder",
            model_client=client,
            system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¨‹åºå‘˜ï¼Œè¯·ç¼–å†™é«˜è´¨é‡ã€å¯è¯»æ€§å¼ºçš„ä»£ç ã€‚"
        )
        
        for i, coding_task in enumerate(coding_tasks, 1):
            print(f"\nğŸ“ ä»»åŠ¡ {i}: {coding_task['title']}")
            print(f"è¦æ±‚: {coding_task['task']}")
            print("ğŸ’» å®ç°:")
            
            try:
                response = await agent.run(task=coding_task['task'])
                print(response.messages[-1].content)
                print("\n" + "-"*60)
                
            except Exception as e:
                print(f"âŒ é”™è¯¯: {str(e)}")
        
        await client.close()


async def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ¨ AutoGen ç¼–ç¨‹ä»£ç†æ¼”ç¤º")
    print("ğŸ“š å±•ç¤ºå¤šæ¨¡å‹åä½œå’Œç¼–ç¨‹èƒ½åŠ›")
    print("="*80)
    
    # é€‰æ‹©æ¼”ç¤ºæ¨¡å¼
    print("è¯·é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
    print("1. å¤šä»£ç†åä½œæ¼”ç¤º (æ¨è)")
    print("2. å•æ¨¡å‹ç¼–ç¨‹æµ‹è¯•")
    print("3. ä¸¤è€…éƒ½è¿è¡Œ")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
    
    if choice in ["1", "3"]:
        await coding_collaboration_demo()
    
    if choice in ["2", "3"]:
        await single_model_coding_test()
    
    if choice not in ["1", "2", "3"]:
        print("ğŸ”„ é»˜è®¤è¿è¡Œåä½œæ¼”ç¤º...")
        await coding_collaboration_demo()
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())